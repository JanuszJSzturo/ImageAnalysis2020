{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import mnist_reader\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage import data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.array([[0,0,1,1],[0,0,1,1],[0,2,2,2],[2,2,3,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 2, 2, 2],\n",
       "       [2, 2, 3, 3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bfb5b9aef0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm = greycomatrix(test_img,[1],[np.pi/2],4,symmetric=True,normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25       0.         0.08333333 0.         0.         0.16666667\n",
      " 0.08333333 0.         0.08333333 0.08333333 0.08333333 0.08333333\n",
      " 0.         0.         0.08333333 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(glcm.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLDV (Grey-level difference vector)\n",
    "def gldv(glcm):\n",
    "    gldv = np.zeros(len(glcm))\n",
    "    for i in range(len(glcm)):\n",
    "        if(i>0):\n",
    "            gldv[i]=np.trace(glcm, offset=i)*2\n",
    "        else:\n",
    "            gldv[i]=np.trace(glcm, offset=i)\n",
    "            \n",
    "    return gldv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gldv(glcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.33333333, 0.16666667, 0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLCM  Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLCM proerties from skiimage  \n",
    "greycoprops(GLCM, prop='measure')  \n",
    "measure   \n",
    "‘contrast’: $\\sum_{i,j=0}^{levels-1} P_{i,j}(i-j)^2$  \n",
    "‘dissimilarity’: $\\sum_{i,j=0}^{levels-1} P_{i,j}|i-j|$  \n",
    "‘homogeneity’ : $\\sum_{i,j=0}^{levels-1} \\frac{P_{i,j}}{1+(i-j)^2}$  \n",
    "‘ASM’$\\sum_{i,j=0}^{levels-1} P^2_{i,j}$   \n",
    "‘energy’ $\\sqrt{ASM}$  \n",
    "‘correlation’  $\\sum_{i,j=0}^{levels-1} P_{i,j}\\frac{(i-\\mu_i)(j-\\mu_j)}{\\sqrt{\\sigma_i^2\\sigma_j^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glcm_props (glcm):\n",
    "    #contrast = greycoprops(glcm,'contrast')\n",
    "    dissimilarity = greycoprops(glcm,'dissimilarity')\n",
    "    #homogeneity = greycoprops(glcm,'homogeneity')\n",
    "    #ASM = greycoprops(glcm,'ASM')\n",
    "    #energy = greycoprops(glcm,'energy')\n",
    "    correlation = greycoprops(glcm,'correlation')\n",
    "    return np.array([dissimilarity, correlation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Zalando fashion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntamos ambos datasets, ya que vamos a crear nuestro propio dataset más pequeño. La carga de datos que proponen es para realizar un entranamiento de una red neruonal, en nuestro caso vamos a obtener descriptores de las imágenes y utilizar un KNN para realizar la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.concatenate((X_train,X_test))\n",
    "Y_dataset = np.concatenate((y_train,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make own dataset (smaller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De todo el conjunto queremos sacar 100 elementos de 4 clases para obtener los descriptores y clasificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sample(X, Y, labels, elements = 100):\n",
    "    # labels: array con las clases que queremos coger entre 0 y 9 incluidos.\n",
    "    \n",
    "    # elements: especificamos cuántos elementos de cada clase queremos coger, máximo de 7000 ya que el conjunto de\n",
    "    # Zalando tiene 6000+1000 en train+test para cada clase\n",
    "    \n",
    "    #Creamos nuestro propio dataset reducido\n",
    "    my_X_dataset = np.zeros((elements*len(labels),28*28))\n",
    "    my_Y_dataset = np.zeros(elements*len(labels))\n",
    "    for i in range(len(labels)):\n",
    "        ind = (Y==labels[i])\n",
    "        my_X_dataset[i*elements:elements*(i+1),] = X[ind][0:elements]\n",
    "        my_Y_dataset[i*elements:elements*(i+1)] = Y[ind][0:elements]\n",
    "\n",
    "    my_X_dataset = my_X_dataset.astype(np.uint8)\n",
    "    my_Y_dataset = my_Y_dataset.astype(np.uint8)\n",
    "    return my_X_dataset, my_Y_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_X_dataset, my_Y_dataset = my_sample(X_dataset, Y_dataset, elements=100, labels = [4,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos nuestro dataset en train y test mediante el uso de train_test_split de scikit-learn\n",
    "my_X_train, my_X_test, my_y_train, my_y_test = train_test_split(my_X_dataset, my_Y_dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[82 82 82 74]\n"
     ]
    }
   ],
   "source": [
    "# Revisamos la distribución que ha hecho scikit de los datos\n",
    "u, counts = np.unique(my_y_train, return_counts=True)\n",
    "print(u)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular las GLCM y sus métricas. Devuelve las GLCM y sus métricas.\n",
    "# Suponemos que se pasa un dataset de [N,(28*28)] imágenes en escala de grises\n",
    "def calc_glcm (dataset):\n",
    "    measures = np.zeros([len(dataset),2])\n",
    "    # Calulamos todas las medidas para cada imagen.\n",
    "    glcm_hists = np.zeros([len(dataset),256*256])\n",
    "    for i in range(len(measures)):\n",
    "        image = my_X_train[i].reshape(28,28).copy()\n",
    "        glcm = greycomatrix(image,distances=[1],angles=[0],levels=256,symmetric=True,normed=True)\n",
    "        glcm_hists[i,:] = glcm.flatten()\n",
    "        measures[i,:] = glcm_props(glcm).flatten()\n",
    "    return glcm_hists, measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular las GLCM y sus métricas. Devuelve las GLCM y sus métricas.\n",
    "# Suponemos que se pasa un dataset de [N,(28*28)] imágenes en escala de grises\n",
    "def calc_glcm2 (dataset):\n",
    "    measures = np.zeros([len(dataset),2])\n",
    "    # Calulamos todas las medidas para cada imagen.\n",
    "    glcm_hists = np.zeros([len(dataset),16*16])\n",
    "    for i in range(len(measures)):\n",
    "        image = my_X_train[i].reshape(28,28).copy()\n",
    "        image = np.floor(image/16)\n",
    "        image = image.astype(np.uint8)\n",
    "        glcm = greycomatrix(image,distances=[1],angles=[0],levels=16,symmetric=True,normed=True)\n",
    "        glcm_hists[i,:] = glcm.flatten()\n",
    "        measures[i,:] = glcm_props(glcm).flatten()\n",
    "    return glcm_hists, measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm_hist_train , measures_train = calc_glcm(my_X_train)\n",
    "glcm_hist_test , measures_test = calc_glcm(my_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_chisquare (H1, H2):\n",
    "    return sum((H1-H2)**2/(H1+1e6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.333333333333333"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "b = np.array([2,2,2,2])\n",
    "sum((a-b)**2/a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 6, 7],\n",
       "       [6, 4, 3, 5],\n",
       "       [7, 1, 1, 9],\n",
       "       [9, 7, 4, 6]], dtype=int64)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_glcm = KNeighborsClassifier(n_neighbors=3, metric=hist_chisquare)\n",
    "neigh_glcm.fit(glcm_hist_train, my_y_train)\n",
    "y_pred_glcm = neigh_glcm.predict(glcm_hist_test)\n",
    "print(accuracy_score(my_y_test, y_pred_glcm))\n",
    "confusion_matrix(my_y_test, y_pred_glcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 3, 6, 7],\n",
       "       [6, 4, 3, 5],\n",
       "       [6, 1, 2, 9],\n",
       "       [9, 7, 4, 6]], dtype=int64)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_glcm = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh_glcm.fit(glcm_hist_train, my_y_train)\n",
    "y_pred_glcm = neigh_glcm.predict(glcm_hist_test)\n",
    "print(accuracy_score(my_y_test, y_pred_glcm))\n",
    "confusion_matrix(my_y_test, y_pred_glcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glcm_hist_train , measures_train = calc_glcm2(my_X_train)\n",
    "glcm_hist_test , measures_test = calc_glcm2(my_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 6, 3],\n",
       "       [5, 5, 3, 5],\n",
       "       [7, 3, 3, 5],\n",
       "       [9, 6, 5, 6]], dtype=int64)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_glcm = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh_glcm.fit(glcm_hist_train, my_y_train)\n",
    "y_pred_glcm = neigh_glcm.predict(glcm_hist_test)\n",
    "print(accuracy_score(my_y_test, y_pred_glcm))\n",
    "confusion_matrix(my_y_test, y_pred_glcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5,  5,  4],\n",
       "       [10,  6,  1,  1],\n",
       "       [ 6,  5,  2,  5],\n",
       "       [11,  8,  4,  3]], dtype=int64)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_measures = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh_measures.fit(measures_train, my_y_train)\n",
    "y_pred_measures = neigh_measures.predict(measures_test)\n",
    "print(accuracy_score(my_y_test, y_pred_measures))\n",
    "confusion_matrix(my_y_test, y_pred_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para ajustar el descriptor HOG\n",
    "winSize = (28,28) # Tamaño de nuestra imagen directamente porque queremos un descriptor para toda la imagen\n",
    "blockSize = (14,14) # \n",
    "blockStride = (7,7)\n",
    "cellSize = (14,14)\n",
    "nbins = 9\n",
    "derivAperture = 1 # No cambiar\n",
    "winSigma = -1. # No cambiar\n",
    "histogramNormType = 0 # No cambiar\n",
    "L2HysThreshold = 0.2 # No cambiar\n",
    "gammaCorrection = 1 # No cambiar\n",
    "nlevels = 64 # No cambiar\n",
    "useSignedGradients = True\n",
    "\n",
    "# Descriptor HOG con los parámetros anteriores\n",
    "hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,histogramNormType,L2HysThreshold,gammaCorrection,nlevels, useSignedGradients)\n",
    "\n",
    "# Suponemos que se pasa un dataset de [N,(28*28)] imágenes en escala de grises\n",
    "def calc_hog (dataset):\n",
    "    hog_descriptors = np.zeros([len(dataset),81])\n",
    "    for i in range(len(dataset)):\n",
    "        hog_descriptors[i,:] = hog.compute(dataset[i].reshape(28,28)).flatten()\n",
    "    return hog_descriptors   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_descriptors_train = calc_hog(my_X_train)\n",
    "hog_descriptors_test =calc_hog(my_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18,  0,  0,  0],\n",
       "       [ 0, 13,  1,  4],\n",
       "       [ 0,  0, 15,  3],\n",
       "       [ 1,  4,  2, 19]], dtype=int64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_hog = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh_hog.fit(hog_descriptors_train, my_y_train)\n",
    "y_pred_hog = neigh_hog.predict(hog_descriptors_test)\n",
    "print(accuracy_score(my_y_test, y_pred_hog))\n",
    "confusion_matrix(my_y_test, y_pred_hog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VPC Py38",
   "language": "python",
   "name": "visio_per_computador"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
